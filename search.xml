<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>四月末尾的夜晚</title>
      <link href="/2023/04/29/%E5%9B%9B%E6%9C%88%E6%9C%AB%E5%B0%BE%E7%9A%84%E5%A4%9C%E6%99%9A/"/>
      <url>/2023/04/29/%E5%9B%9B%E6%9C%88%E6%9C%AB%E5%B0%BE%E7%9A%84%E5%A4%9C%E6%99%9A/</url>
      
        <content type="html"><![CDATA[<h3 id="四月末尾的夜晚"><a href="#四月末尾的夜晚" class="headerlink" title="四月末尾的夜晚"></a>四月末尾的夜晚</h3><br><p>月亮似乎并不明亮</p><p>远处彻夜的亮着的路灯是城市的光明</p><p>是别人的夜晚</p><p>我的内心只有月亮，月亮就要熄灭<br><br></p><p>悔恨的泪水流出来</p><p>流满了整个湖泊</p><p>内心的恐惧也如深渊一般</p><p>无法跨越<br><br></p><p>四月就这样到来又离去</p><p>未知的五月伸出利爪抓挠着我内心的防线</p><p>不如死在四月的末尾</p><p>就死在春天的尾巴上面</p>]]></content>
      
      
      <categories>
          
          <category> 其他 </category>
          
          <category> 诗歌 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 四月 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>考公日记</title>
      <link href="/2023/04/12/%E8%80%83%E5%85%AC%E6%97%A5%E8%AE%B0/"/>
      <url>/2023/04/12/%E8%80%83%E5%85%AC%E6%97%A5%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="考公日记"><a href="#考公日记" class="headerlink" title="考公日记"></a>考公日记</h2><h3 id="意外进面"><a href="#意外进面" class="headerlink" title="意外进面"></a>意外进面</h3><p>&ensp;&ensp;&ensp;&ensp;说实话，对于省考进面试的这个结果我是挺意外的。我看到这个消息的时候还在我妈妈工作的那个工厂里工作——听我的老板跟我讲一些我认为没有营养的一些话。当然我认为我这个老板还是不错的。似乎当你不把一件事情放在心上，当你以为它已经失败了的时候，它好像总是能成功。反过来好像也是这样，当你把一件事放在心上，并全力以赴时，事情总难以得到让人满意的结果。命运好像总是这样捉弄人。</p><p>&ensp;&ensp;&ensp;&ensp;当时由于各种原因，其实并没有为省考准备太多，以至于我都打算在我妈妈的那个工厂里先混到毕业，等拿到毕业证再谋求一份好一点的工作，可是老天似乎想要给我一点机会，一点点幸运，看我是否能把握住。看到这个消息的时候，内心还是蛮兴奋的，觉得自己的考公之路又有了着落。我的笔试成绩并不算高，说到底还是幸运。另一个同为应届岗的岗位有三个七十多分的大佬，我在那个岗位可能要排到第十左右了。我还是幸运的，第一次考试就进面了。</p><h3 id="报班前夕"><a href="#报班前夕" class="headerlink" title="报班前夕"></a>报班前夕</h3><p>&ensp;&ensp;&ensp;&ensp;查分过后，我在华图的一个小程序上晒了分数，当时在那个名单排第四，我心里觉得这还挺高的。当排名出来后，第八。我还是数错了，去跟人家说我的情况是招五排七。 😢 总之是进面了，跟第五名也是只差0.9分。当时很多华图的老师给我打电话，但那时还是很犹豫，一是太贵了，二是对自己的怀疑。</p><p>&ensp;&ensp;&ensp;&ensp;面对多种情况，对于一仁教育和华图我最终选择了华图。从众心理作祟，以及自己的小算盘——考不上一分钱不拿。对于乡镇岗位，拿成绩来看，一仁教育确实比华图的数据更加好看，同时一仁教育也更加便宜。</p><h3 id="线下面试班"><a href="#线下面试班" class="headerlink" title="线下面试班"></a>线下面试班</h3><p>&ensp;&ensp;&ensp;&ensp;线下面试班说实话也有点辛苦，每天要从早上七点半到晚上的十点半左右，高中过后再没有体验过的早读又享受到了。每天都很困，面试班的内容也听得不是很明白，一知半解的，就开始模拟训练。每天都会很疑惑，今天到底学了啥，也不知道自己是不是学明白了。当然最后的面试也算告诉我了答案。我也不能说是不努力吧，当然可能确实没尽全力。</p><p>&ensp;&ensp;&ensp;&ensp;线下面试班里的同学确实都很厉害，首先对我的打击可能就是在学历上，大家都是乡镇岗位，我一个大专生，不说里面大都是本科生，甚至研究生去报乡镇岗位是我不能理解的，这也让我深刻体会到了考公如此之卷。我一直认为学历是能力的一种体现。大家一般学校越好的学习能力也越强，理解能力也越强。其实他们中有些人有丰富的阅历，丰富的人生经验让他们在面对同一道面试题中有更多的切实可行的方案，有些人有良好的学习和记忆能力，之前对申论的刻苦学习使得他们在面对同一道面试题中更加从容，好像只有自己是纯靠运气走到了这里。</p><h3 id="面试失败"><a href="#面试失败" class="headerlink" title="面试失败"></a>面试失败</h3><p>&ensp;&ensp;&ensp;&ensp;我的面试时间是9号，也不知道是运气好还是不好，当时一方面想着7号面试，早日结束痛苦，但是又想着再慢些，再多给自己一些时间练习。面试前华图给我们找个两个经验丰富的考官。第二个考官反复提及<strong>大兴调研之风</strong>,<strong>大田变小田</strong>，我虽然注意了，但没有放在心上。全真模拟时两位老师给我打的分数都在74分左右，最后我也真的只考了73.8分。<br></p><h3 id="以后"><a href="#以后" class="headerlink" title="以后"></a>以后</h3><p>&ensp;&ensp;&ensp;&ensp;<strong>路漫漫其修远兮，吾将上下而求索</strong></p>]]></content>
      
      
      <categories>
          
          <category> 其他 </category>
          
          <category> 考公 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 思考 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytho爬虫—urllib</title>
      <link href="/2023/03/14/pytho%E7%88%AC%E8%99%AB%E2%80%94urllib/"/>
      <url>/2023/03/14/pytho%E7%88%AC%E8%99%AB%E2%80%94urllib/</url>
      
        <content type="html"><![CDATA[<h1 id="urllib"><a href="#urllib" class="headerlink" title="urllib"></a>urllib</h1><h2 id="一、urllib库的基本使用"><a href="#一、urllib库的基本使用" class="headerlink" title="一、urllib库的基本使用"></a>一、urllib库的基本使用</h2><pre><code>urllib.request.urlopen() 模拟浏览器向服务器发送请求   response    服务器返回的数据        response的数据类型是HttpResponse            字节‐‐&gt;字符串                解码 decode                    字符串‐‐&gt;字节                编码 encoderead()       字节形式读取二进制网页源码   扩展：rede(5)返回前几个字节        readline()   读取一行        readlines()  一行一行读取 直至结束        getcode()    获取状态码        geturl()     获取url        getheaders() 获取headersurllib.request.urlretrieve()        请求网页            请求图片            请求视频</code></pre><h2 id="Urllib库的基本使用——获取百度一下的页面源码"><a href="#Urllib库的基本使用——获取百度一下的页面源码" class="headerlink" title="Urllib库的基本使用——获取百度一下的页面源码"></a>Urllib库的基本使用——获取百度一下的页面源码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 引入urllib库</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义url</span></span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟浏览器访问，获取响应数据</span></span><br><span class="line">response = urllib.request.urlopen(url=url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line"><span class="comment"># 由于response返回的数据是二进制的字节，所以对其进行解码</span></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印</span></span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure><h2 id="二、请求对象的定制"><a href="#二、请求对象的定制" class="headerlink" title="二、请求对象的定制"></a>二、请求对象的定制</h2><p>UA介绍：User Agent中文名为用户代理，简称 UA，它是一个特殊字符串头，使得服务器能够识别客户使用的操作系统<br>及版本、CPU 类型、浏览器及版本。浏览器内核、浏览器渲染引擎、浏览器语言、浏览器插件等</p><pre><code>语法：request = urllib.request.Request()</code></pre><h2 id="编解码"><a href="#编解码" class="headerlink" title="编解码"></a>编解码</h2><h3 id="1-get请求"><a href="#1-get请求" class="headerlink" title="1.get请求"></a>1.get请求</h3><h4 id="urllib-parse-quote（）"><a href="#urllib-parse-quote（）" class="headerlink" title="urllib.parse.quote（）"></a>urllib.parse.quote（）</h4><p>eg:使用百度搜索周杰伦<br><br>获取    <a href="https://www.baidu.com/s?wd=%E5%91%A8%E6%9D%B0%E4%BC%A6">https://www.baidu.com/s?wd=周杰伦</a>  的网页源码,由于周杰伦三个为汉字，所以需要对其进行编码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 引入所需库</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义url</span></span><br><span class="line">base_url = <span class="string">&#x27;url = &#x27;</span>https://www.baidu.com/s?wd=<span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 依赖urllib.parse，将周杰伦三个汉字转换为Unicode编码</span></span><br><span class="line">name = urllib.parse.quote(<span class="string">&#x27;周杰伦&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 组成完整的url</span></span><br><span class="line">url += name</span><br><span class="line">    </span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36 Edg/109.0.1518.78&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 定制请求对象</span></span><br><span class="line">request = urllib.request.Request(url, <span class="literal">None</span>, headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取响应</span></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure><h4 id="urllib-parse-urlencode-字典对象"><a href="#urllib-parse-urlencode-字典对象" class="headerlink" title="urllib.parse.urlencode(字典对象)"></a>urllib.parse.urlencode(字典对象)</h4><p>urllib.parse.urlencode(字典对象)，将字典的每一个元素转换为unicode编码，并用&amp;将每一个元素进行相连</p><p>eg: <a href="https://www.baidu.com/s?wd=%E5%91%A8%E6%9D%B0%E4%BC%A6&sex=%E7%94%B7">https://www.baidu.com/s?wd=周杰伦&amp;sex=男</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line">base_url = <span class="string">&#x27;https://www.baidu.com/s?&#x27;</span></span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;wd&#x27;</span>: <span class="string">&#x27;周杰伦&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sex&#x27;</span>: <span class="string">&#x27;男&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;location&#x27;</span>: <span class="string">&#x27;中国台湾省&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">keyword = urllib.parse.urlencode(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求资源路径</span></span><br><span class="line">url = base_url + keyword</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36 Edg/109.0.1518.78&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 定制请求 对象</span></span><br><span class="line">request = urllib.request.Request(url, <span class="literal">None</span>, headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟浏览器向服务器发送请求</span></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"><span class="comment"># 获取网页源码数据</span></span><br><span class="line"></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure><h2 id="爬取百度翻译结果（post请求）"><a href="#爬取百度翻译结果（post请求）" class="headerlink" title="爬取百度翻译结果（post请求）"></a>爬取百度翻译结果（post请求）</h2><p>使用python代码爬取百度翻译的简单结果<br>    : 首先要引入所需的库，urllib<br>    : 在百度翻译的网页中找到请求数据的网址为：<a href="https://fanyi.baidu.com/sug">https://fanyi.baidu.com/sug</a><br>    : 查看负载的数据，写入data中<br>    : 对于post请求必须进行编码，编码过后要记得解码<br>    : 随后利用urllib.request.Request() 定制响应请求头<br>    : 之后模拟在浏览器中访问，获取响应，读取响应<br>    : 由于读取的内容为文本数据，但是原内容为json数据，所以未正确显示，引入json库，将其转为json数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 引入库</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 基础路径</span></span><br><span class="line">base_url = <span class="string">&#x27;https://fanyi.baidu.com/sug&#x27;</span></span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;kw&#x27;</span>: <span class="string">&#x27;spider&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># data中的数据可以替换为用户输入的数据</span></span><br><span class="line">data[<span class="string">&#x27;kw&#x27;</span>] = <span class="built_in">str</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入要查询的英文单词：&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># post 请求必须编码，编码后需要解码</span></span><br><span class="line">data = urllib.parse.urlencode(data).encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36 Edg/109.0.1518.78&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(url=base_url,data=data,headers=headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取响应</span></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取响应内容</span></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 字符串 ---&gt; json</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line">obj = json.loads(content)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取响应内容</span></span><br><span class="line"><span class="built_in">print</span>(obj)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> python爬虫 </category>
          
          <category> urllib </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> python爬虫 </tag>
            
            <tag> urllib </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在深夜的火车上</title>
      <link href="/2023/03/11/%E5%9C%A8%E6%B7%B1%E5%A4%9C%E7%9A%84%E7%81%AB%E8%BD%A6%E4%B8%8A/"/>
      <url>/2023/03/11/%E5%9C%A8%E6%B7%B1%E5%A4%9C%E7%9A%84%E7%81%AB%E8%BD%A6%E4%B8%8A/</url>
      
        <content type="html"><![CDATA[<p>下午四五点钟，我动身从家前往南京，一是跟姐姐们玩耍，二是为了我的工作。<br>关于工作我总是矛盾且犹豫。我找不到我心仪的工作，有不愿意去厂区打螺丝获取饭店端盘子。</p><blockquote><p>“如果我没上大学就好了，就可以心安理得去当服务员，可是我上了大学拉不下脸。”<br>“如果我没上大学，就可以找一位没有学历门槛的工作，不用现在这样进退两难。”<br>“我真的很想当美甲师，可我都读到硕士了，家里人肯定接受不了。”</p></blockquote><p>这是上海外国语大学一位硕士的演讲，我们都自然而然的带入，抖音上也掀起来一股“孔乙已文学”。我也是自然将我自己代入了进去的。可我并不如孔乙已，孔乙已知道茴字有四种写法。但我由于我现在的处境，我同样开始怀疑我自己。如果我没有读书，我真的可以心安理得的去打螺丝，去做服务员。可我读了三年大学，虽然我觉得读这个学校是个错误的决定，但我依旧觉得我读了三年大学，应该去做一份看起来比较体面的工作。<br>并不是我脱不下所谓什么孔乙已的长衫，我在合肥找工作时我面试了两家客服，都拒绝了我。对此我并不是很能理解，我不明白做一个客服的技术含量在哪？难道我不如一个高中生吗？那之前我就早已经开始怀疑自己。我觉得似乎我高考过后做的每一个决定都是错的。我看着周围的同学好像都在往前走，只有我在原地踏步。加上我现在没有工作，我每天都很拧巴。我也想过去做一些下力气的活，但我又想再等等。等我公务员考试成绩下来，等我考完事业单位联考……<br>我总是如此，犹豫不决，没有主见。有点烂，不，简直烂透了。自己还以为自己多厉害多厉害，看不起周遭所有人。觉得这个不知进取，自甘堕落，觉得那个曲意逢迎，阿谀奉承，还觉得他们满嘴谎言，道德低下。可是当这些劣根展现到你身上时你为什么没有察觉呢？假清高，装深沉！<br>这列火车向前开，中转南京。你往哪走，在哪中转，在哪到达终点？</p><blockquote><p>要紧的是果敢地迈出第一步，对与错先都不管，自古就没有把一切都设计好再开步的事</p></blockquote><p>鲁莽者要学会思考，善思者要克服犹豫。我总是矛盾，犹豫不决，拿不定主意。我想我这样的人别说是什么大事了，也许现在连小事情做起来也开始费劲了。然而还是要迈出第一步，勇敢的迈出第一步，我不能不能在原地等死。无论我要参加事业单位联考，还是继续找工作，我都要开始迈出这一步了，我不能再停留在原地。</p><blockquote><p>春风得意马蹄疾，一日看尽长安花</p></blockquote><p>望诸君顺遂，勇敢踏出心中的那一步。</p>]]></content>
      
      
      <categories>
          
          <category> 其他 </category>
          
          <category> 生活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 思考 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HelloWorld</title>
      <link href="/2023/03/09/HelloWorld/"/>
      <url>/2023/03/09/HelloWorld/</url>
      
        <content type="html"><![CDATA[<h3 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h3>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
